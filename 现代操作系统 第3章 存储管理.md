# 现代操作系统 第3章 存储管理

- 内存（RAM）是计算机中一种需要认真管理的重要资源
- 帕金森定律：不管存储器多大，程序都可以把它填满
- 分层存储体系，memory hierarchy
- 操作系统中管理分层存储器体系的部分称为存储管理器（memory manager）
  - 有效地管理内存

## 3.1 无存储器抽象

- 最简单的存储器抽象就是根本没有抽象
- 存储器模型就是简单的物理内存：从0到某个上限的地址集合，每个地址对应一个可容纳一定数目二进制位的存储单元，通常是8个
- 三种变体
  - 操作系统位于RAM（随机访问存储器）的底部
    - 以前被用在大型机和小型计算机上
  - 操作系统位于内存顶端的ROM中（只读存储器）中
    - 被用在一些掌上电脑和嵌入式系统中
  - 设备驱动程序位于内存顶端的ROM中，而操作系统的其他部分则位于下面的RAM的底部
    - 用于早期的个人计算机
    - 在ROM的系统部分称为BIOS（Basic Input Output System，基本输入输出系统）
- 当按这种方式组织系统时，通常同一个时刻只能有一个进程在运行
- 在没有内存抽象的系统中实现并行的一种方法是使用多线程来编程
- 在不适用内存抽象的情况下运行多道程序
  - 操作系统值需要把当前内存中所有内容保存到磁盘文件中，然后把下一个程序读入到内存中再运行即可
- 直接引用物理地址对于大型计算机、小型计算机、台式计算机和笔记本电脑来说已经成为很久远的记忆
  - 但是缺少内存抽象情况下的嵌入式系统和智能卡系统中还是很常见的
  - 操作系统作为库实现
    - e-cos操作系统

## 3.2 一种存储器抽象：地址空间

- 把物理地址暴露给进程会带来下面几个严重的问题：
  - 如果用户程序可以寻址到内存的每个字节，它们就可以很容易地破坏操作系统
  - 使用这种模型，想要同时运行多个程序是很困难的

### 3.2.1 地址空间的概念

- 要保证多个应用程序同时处于内存中并不互相影响，则需要解决两个问题：
  - 保护
    - 给内存块标记上一个保护键，并且比较执行进程的键和其访问的每个内存字的保护键
  - 重定向
    - 创造一个新的内存抽象：地址空间
- 地址空间是一个进程可用于寻址内存的一套地址空间
  - 每个进程都有一个自己的地址空间，这个地址空间独立于其他进程的地址空间
- 地址空间的概念非常通用，并且在很多场合中出现
  - 电话号码地址空间从0000000到9999999
  - Pentium的I/O端口的地址空间从0到16383
  - IPv4的地址是32位的数字，因此他们的地址空间从0到2^32-1
  - 一套“.com"的互联网域名也是地址空间，由所有包含2~63个字符并且后面跟着“.com"的字符串组成
- 基址寄存器与界限寄存器
  - 这个简单的解决办法使用一种简单的动态重定位
    - 简单地把每个进程的地址空间映射到物理内存的不同部分
    - 给每个CPU配置两个特殊硬件寄存器，通常叫做基址寄存器和界限寄存器
      - 当一个进程运行时，程序的起始物理地址装载到基址寄存器中，程序的长度装载到界限寄存器中
  - 使用基址寄存器和界限寄存器是给每个进程提供私有地址空间的非常容易地方法
  - 使用基址寄存器和界限寄存器重定位的缺点是
    - 每次访问内存都需要进程加法和比较运算

### 3.2.2 交换技术

- 在一个典型的Windows或Linux系统中，在计算机完成引导后，会启动40~60个，甚至更多的进程
- 两种处理内存超载的通用方法
  - 交换技术，swapping
    - 最简单的策略
    - 把一个进程完整调入内存，使该进程运行一段时间，然后把它存回磁盘
  - 虚拟内存，virtual memory
    - 使程序在一部分被调入内存的情况下运行
- 内存紧缩，memory compaction
  - 交换在内存中产生了多个空闲区（hole，也称空洞），通过把所有的进程尽可能向下移动，有可能将这些小的空闲区合成一大块
  - 如果大部分进程在运行时都要增长，为了减小因内存不够而引起的进程交换和移动所产生的开销
    - 一种可用的方法是，当换入或移动进程时为它分配一些额外的内存

### 3.2.3 空闲内存管理

- 动态分配内存时，操作系统必须对其进行管理
  - ·有两种方式跟踪内存使用情况
    - 位图
    - 空闲链表
- 使用位图的存储管理
  - 使用位图方法时，内存可能被划分成小刀几个字或大到几千字节的分配单位
    - 每个分配单位对应于位图中的一位，0表示空闲，1表示占用
    - ​
  - 分配单位的大小是一个重要的设计因素
    - 分配单位越小，位图越大
  - 这种方法的主要问题是，在决定把一个占k个分配单元的进程调入内存时，存储管理器必须搜索位图，在位图中找出有k个连续0的串
    - 查找位图中指定长度的连续0串是耗时的操作（因为在位图中该串可能跨越字的边界
- 使用链表的存储管理
  - 另一种记录内存使用情况的方法是，维护一个记录已分配内存段和空闲内存段的链表
    - 链表的一个结点或者包含一个进程，或者是两个进程间的一个空的空闲区
    - 链表中的每个节点都包含以下域
      - 空闲区（H）
      - 进程（P）的指示标志、起始位置、长度和指向下一结点的指针
  - 段链表是按照地址排序的，其好处是当进程终止或被换出时链表的更新非常直接
  - 当按照地址顺序在链表中存放进程和空闲区时，有几种算法可以用来为创建的进程分配内存
    - 首次适配算法，first fit
      - 存储管理器沿着段链表进行搜索，直到找到一个足够大的空闲区，除非空闲区大小和要分配的空间大小正好一样，否则将空闲区分为两部分，一部分供进程使用，另一部分形成新的空闲区
      - 一种速度很快的算法，因为它尽可能少地搜索链表节点
    - 下次适配，next fit
      - 它的工作方式和首次适配算法相同，不同的是每次找到合适的空闲区时都记录当时的位置
        - 以便在下次寻找空闲区时从上次结束的地方开始搜索，而不是像首次适配算法那样每次都从头开始
      - 性能略低于首次适配算法
    - 最佳适配，best fit
      - 搜索整个链表（从开始到结束），找出能够容纳进程的最小的空闲区
      - 最佳适配的空闲区会分裂出很多非常小的空闲区，为了避免这一问题，可以考虑最差适配算法
    - 最差适配，worst fit
      - 总是分配最大的可用空闲区
    - 快速适配，quick fit
      - 为那些常用大小的空闲区维护单独的链表

## 3.3 虚拟内存

- 管理软件的膨胀，bloatware
  - 需要运行的程序往往大到内存无法容纳，而且必然需要系统支持多个程序同时运行
- 20世纪60年代所采用的方法是
  - 覆盖，overlay
    - 把程序分割成许多片段
    - 程序开始时，将覆盖管理模块装入内存，该管理模块立即装入并运行覆盖0。执行完成后，覆盖0通知管理模块装入覆盖1，或者占用覆盖0的上方位置，或者占用覆盖0
- 虚拟内存，virtual memory
  - 基本思想是，每个程序拥有自己的地址空间，这个空间被分割成多个块，每一块称作一页或页面（page）
    - 当程序引用到一部分在物理内存中的地址空间时，由硬件立刻执行必要的映射
    - 当程序引用到有部分不在物理内存中的地址空间时，有操作系统负责将缺失的部分装入物理内存并重新执行失败的指令
  - 从某种角度来讲，虚拟内存是对基址寄存器和界限寄存器的一种综合
  - 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中

### 3.3.1 分页

- 分页，paging
  - 大部分虚拟机内存系统中都使用
  - 在任何一台计算机上，程序引用一组内存地址
    - 地址可以通过索引、基址寄存器、段寄存器或其他方式产生
    - 由程序产生的这些地址称为虚拟地址（virtual address）它们构成一个虚拟地址空间（virtual address space）
  - 在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字
  - 在使用虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是被送到内存管理单元（Memory Management Unit，MMU），MMU把虚拟地址映射为物理内存地址
  - 虚拟地址空间按照固定大小划分成称为页面（page）的若干单元
    - 在物理内存中对应的单元称为页框（page frame）
    - 页面和页框的大小通常是一样的
    - RAM和磁盘之间的交换总是以整个页面为单元进行的
  - 在实际的硬件中，用一个“在/不在”位（present/absent bit）记录页面在内存中的实际存在情况
  - 缺页中断，page fault
    - 使CPU陷入到操作系统

### 3.3.2 页表

- 虚拟地址到物理地址的映射概括如下：
  - 虚拟地址被分成虚拟页号（高位部分）和偏移量（地位部分）两部分
  - 虚拟页号可用作页表的索引，以找到该虚拟页面对应的页表项。由页表项可以找到页框号。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成送往内存的物理地址
  - 页表的目的是把虚拟页面映射为页框
- 页表项的结构
  - 页表项的结构是与机器密切相关的，但不同机器的页表项存储的信息都大致相同
    - 32位是常用的大小
    - 最重要的域是页框号
    - 其次是“在/不在”位
    - ”保护“（protection）位指出一个页允许什么类型的访问
    - 为了记录页面的使用状况，引入了“修改”（modified）位和“访问”（referenced）位
      - 在写入一页时有硬件自动设置修改位
        - 该位在操作系统重新分配页框时是非常有用的
      - dirty bit，脏位
        - 如果一个页面已经被修改过（即它是“脏”），则必须把它写回磁盘
        - 如果一个页面没有被修改过（即它是“干净”的），则简单地把它丢弃就好了，因为它在磁盘上的副本仍然是有效的
      - 不论是读还是写，系统都会在该页面被访问时设置访问位
        - 它的值被用来帮助操作系统在发生缺页中断时选择要被淘汰的页面
    - 最后一位用于禁止该页面被高速缓存
- 虚拟内存本质上是用来创造一个新的抽象概念——地址空间
  - 这个概念是对物理地址的抽象
  - 类似于进程是对物理机器（CPU）的抽象
  - 虚拟内存的实现，是将虚拟地址空间分解成页，并将每一页映射到物理内存的某个页框或者（暂时）解除映射

### 3.3.3 加速分页过程

- 在任何分页式系统中，都需要考虑两个主要问题：
  - 虚拟地址到物理地址的映射必须非常快
    - 由于每次访问内存，都需要进程虚拟地址到物理地址的映射
  - 如果虚拟地址空间很大，页表也会很大
    - 现代计算机使用至少32位的虚拟地址，而且64位变得越来越普遍
- 最简单的快速页映射是使用有一组“快速硬件寄存器”组成的单一页表，每个页表项对应一个虚页，虚页作为索引
  - 缺点是页表很大时，代价很高昂
- 另一种极端方法是，整个页表都在内存中
  - 所需要的硬件仅仅是一个指向页表起始位置的寄存器
  - 缺陷是在执行每条指令时，都需要一次或多次内存访问，以完成页表项的读入，速度非常慢
- 转换检测缓冲区
  - 加速页面问题
    - 大多数优化技术都是从内存中的页表开始的
      - 这种设计对效率有着巨大的影响
  - 转换检测缓冲区，Translation Lookaside Buffer，TLB
    - 又称为相联存储器，associate memory
    - 基于只有很少的页表会被反复读取，而其他的页表很少被访问的解决方案
    - 为计算机设置一个小型的硬件设备，将虚拟地址直接映射到物理地址，而不必在访问页表
    - 通常在MMU中，包含少量的表项
      - 每个表项记录了一个页面的相关信息，包括虚拟页号、页面的修改位、保护码（读/写/执行权限）和该页所对应的物理页框
  - TLB如何工作的
    - 将一个虚拟地址放入MMU中进行转换时，硬件首先通过将该虚拟页号与TLB中所有表项同时（即并行）进行匹配，判断虚拟页面是否在其中
- 软件TLB管理
  - 我们假设每一台具有虚拟内存的机器都具有由硬件识别的页表，以及一个TLB
  - 在这种设计中，对TLB的管理和TLB的失效处理都完全由MMU硬件来实现
  - 但是，许多现代的RISC机器，包括SPARC、MIPS以及HP PA，几乎所有的页面管理都是在软件中实现的
    - TLB表项被操作系统显式地装载
    - 当发生TLB访问失效，不再是由MMU到页表中查找并取出需要的页表项，而是生成一个TLB失效并将问题交给操作系统解决
  - 如果TLB大到可以减少失效率时，TLB的软件管理就会变得足够有效
  - 多种不同的策略来改善使用软件TLB管理的机器的性能
    - 其中一种策略是在减少TLB失效的同时，又要发生TLB失效时减少处理开销
  - 无论是用硬件还是用软件来处理TLB失效，常见方法都是找到页表并执行索引操作以定位将要访问的页面
  - 当使用软件TLB管理时，一个基本要求是要理解两种不同的TLB失效的区别在哪里
    - 当一个页面访问在内存中而不在TLB中时，将产生软失效（soft Miss）
    - 当页面本身不在内存中时，将产生硬失效
    - 硬失效的处理时间往往是软失效的百万倍

### 3.3.4 针对大内存的页表

- 在原有的内存页表的方案之上，引入块表（TLB）可以用来加快虚拟地址到物理地址的转换
- 处理巨大的虚拟地址空间的两种解决方法
  - 多级页表
    - 引入多级页表的原因是避免把全部页表一直保存在内存中
    - 虚拟空间地址超过100万个页面，实际上只需要四个页表
      - 顶级页表
      - 0~4M（正文段）
      - 4M~8M（数据段）
      - 顶端4M（堆栈段）的二级页表 
  - 倒排页表
    - 对32位虚拟地址空间，多级页表可以很好地发挥作用
    - 具有64位分页虚拟地址空间的系统需要一个不同的解决方案
      - 倒排页表，inverted page table
      - 在这种设计中，在实际内存中每一个页框有一个表项，而不是每一个虚拟页面有一个表项
      - 严重的不足：
        - 从虚拟地址到物理地址的转换会变得很困难
        - 解决方案是使用TLB
    - 倒排页表在64位机器中很常见，因为在64位机器中即使使用了大页面，页表项的数量还是很庞大的

## 3.4 页面置换算法

- 当发生缺页中断时，操作系统必须在内存中选择一个页面将其换出内存，以便为即将调入的页面腾出空间
- 当发生缺页中断时，虽然可以随机地选择一个页面来置换，但是如果每次都选择不常用的页面会提升系统的性能
- “页面置换”问题在计算机设计的其他领域中也会同样发生
  - 多数计算机把最近使用过的32字节或64字节的存储块保存在一个或多个高速缓存中。当这些过度缓存存满之后就比逊选择一些块丢掉
  - Web服务器
    - 服务器可以把一定数量的进场访问的Web页面存放在存储器的高速缓存中
    - 当存储器高速缓存已满并且要访问一个不在高速缓存中的页面时，就必须要置换高速缓存中的某个Web页面
- 所有页面置换算法中都存在一个问题：
  - 当需要从内存中换出某个页面时，它是否只能是缺页进程本身的页面？
  - 这个要换出的的页面是否可以属于另外一个进程？

### 3.4.1 最优页面置换算法

- 最好的页面置换算法，虽然此算法不可能实现
  - 在缺页中断发生时，有些页面在内存中，其中有一个页面（包含紧接着的下一条指令的那个页面）将很快被访问，其他页面则可能要道10、100或1000条指令后才会被访问，每个页面都可以用在该页面首次被访问前所要执行的指令数作为标记
- 最优页面置换算法规定应该置换标记最大的页面
- 这个算法唯一的问题就是它是无法实现的

### 3.4.2 最近未使用页面置换算法

- 为使操作系统能够收集有用的统计信息，在大部分具有虚拟内存的计算机中，系统为每一页面设置了两个状态位
  - 当页面被访问（读或写）时设置R位
  - 当页面（即修改页面）被写入时设置M位
- 如果硬件没有这些位，则可以进行以下的软件模拟：
  - 当启动一个进程时，将其所有的页面都标记为不在内存；
  - 一旦访问任何一个页面就会引发一次缺页中断，此时操作系统就可以设置R位（在它的内部表格中），修改页表项使其指向正确的页面，并设置为READ ONLY模式，然后重新启动引起缺页中断的指令
  - 如果随后对该页面的修改又引发一次缺页中断，则操作系统设置这个页面的M位并将其改为READ/WRITE模式
- 可以用R位和M位来构造一个简单的页面置换算法：
  - 当启动一个进程时，它的所有页面的两个位都由操作系统设置为0，R位被定期地（比如在每次时钟中断时）清零，以区别最近没有被访问的页面和被访问的页面
- 当发生缺页中断时，操作系统检查所有的页面并根据它们当前的R位和M位的值，把它们分为4类：
  - 第0类：没有被访问，没有被修改
  - 第1类：没有被访问，已被修改
  - 第2类：已被访问，没有被修改
  - 第3类：已被访问，已被修改
- NRU（Not Recently Used，最近未使用）算法
  - 该算法随机地从类编号最小的非空类中挑选一个页面淘汰之
  - 隐含的意思是，在最近一个时钟滴答中（典型的时间是大约20ms）淘汰一个没有被访问的已修改页面要比淘汰一个被频繁使用的“干净”页面好
  - NRU主要有优点是易于理解和能够有效地被实现

### 3.4.3 先进先出页面置换算法

- FIFO，First-In First-out，先进先出算法
  - 另一种开销较小的页面置换算法
  - 由操作系统维护一个所有当前在内存中的页面的链表，最新进入的页面放在表尾，最久进入的页面放在表头
  - 当发生缺页中断时，淘汰表头的页面并把新调入的页面加到表尾
  - 会引起淘汰常用页面
    - 由于这一原因，很少使用纯粹的FIFO算法

### 3.4.4 第二次机会页面置换算法

- FIFO算法可能回吧经常使用的页面置换出去
- 为了避免这一问题，对该算法做一个简单的修改：
  - second chance，第二次机会算法
  - 检查最老页面的R位
    - 如果R位是0，那么这个页面既老又没有被使用，可以立刻置换掉
    - 如果是1，就将R位清0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续搜索
- 第二次机会算法就是寻找一个最近的时钟间隔以来没有被访问过的页面
  - 如果所有的页面都被访问过了，该算法就简化为纯粹的FIFO算法

### 3.4.5 时钟页面置换算法

- 尽管第二次机会算法是一个比较合理的算法，但它要在链表中移动页面，既降低了效率又不是很有必要
- 一个工号的办法是把所有的页面都保存在一个类似钟面的环形链表中，一个表针指向最老的页面
- 当发生缺页中断时，算法首先检查表指向的页面
  - 如果它的R位是0就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置
  - 如果R位是1就清除R位并把表针前移一个位置，重复这个过程直到找到了一个R位为0的页面为止

### 3.4.6 最近最少使用页面置换算法

- 对最优算法得一个很好地近似是基于这样的观察：
  - 在前面几条指令中频繁使用的页面很可能在后面的几条指令中被使用
  - 这个思想提示了一个可实现的算法：
    - LRU，Least Recently Used，最近最少使用页面置换算法
      - 在缺页中断发生时，置换为使用时间最长的页面。
- 虽然LRU在理论上是可以实现的，但代价很高
- 还是有一些使用特殊硬件实现LRU的方法
  - 硬件有一个64位计数器C，它在每条指令执行完后自动加1，每个页表项必须有一个足够容纳这个计数器值的域
  - 在一个有n个页框的机器中，LRU硬件可以维持一个初值为0的n×n位的矩阵

### 3.4.7 用软件模拟LRU

- NFU，Not Frequently Used，最不常用算法
  - 一个能用软件实现的解决方案
  - 该算法每个页面与一个软件计数器先关联，计数器的初值为0
  - 每次时钟中断时，由操作系统扫描内存中所有的页面，将每个页面的R位（它的值是0或1）加到它的计数器上。
  - NFU的主要问题是它从来不忘记任何事情
    - 结果是操作系统将置换有用的页面而不是不再使用的页面
- 只需对NFU做一个小小的修改就能使它很好地模拟LRU
  - 首先，在R位被加进之前先将计数器右移一位
  - 其次，将R位加到计数器最左端的位而不是最右端的位
  - aging，老化算法
    - 发生缺页中断时，将置换计数器值最小的页面
    - 该算法与LRU有两个区别
      - 无法区别在一个时钟滴答中哪个页面在较早的时间被访问以及哪个页面在较晚的时间被访问
      - 老换算法的计数器只有有限位数，这就限制了其对以往页面的记录

### 3.4.8 工作集页面置换算法

- 在单纯的分页系统里，刚启动进程时，在内存中并没有页面
- demand paging，请求调页
  - 一段时间以后，进程需要的大部分页面都已经在内存了，进程开始在较少缺页中断的情况下运行
- 大部分进程都表现出了一种局部性访问行为，即在进程运行的任何阶段，它都只访问较少的一部分页面
- working set，工作集
  - 一个进程当前正在使用的页面的集合
  - thrashing，颠簸
    - 若每执行几条指令就发生一次缺页中断，那么就称这个程序发生了颠簸
- working set model，工作集模型
  - 不少分页系统都会设法跟踪进程的工作集，以确保在让进程运行以前，它的工作集就已经在内存中了
  - 其目的在于大大减小缺页中断率
  - prepaging，预先调页
    - 在让进程运行前预先装入其工作集页面
- 人们很早大多数程序都不是均匀地访问它们的地址空间，而访问往往是集中一小部分页面
  - 工作集是最近k次内存访问所访问过的页面的集合
  - 函数w(w, t)是在时刻t时工作集的大小
  - k的值有一个很大的范围，它处在这个范围中时工作集不会变
    - 预先调用就是在程序继续运行之前预先装入推测出的工作集的页面
- 为了实现工作集模型，一个合理的页面置换算法
  - 当发生缺页中断时，淘汰一个不在工作集中的页面
    - 为了实现工作集算法，必须预先选定k的值
- 一种有效的方法能够在程序运行期间及时地计算出工作集
  - 理论上，当缺页中断发生时，只要读出移位寄存器中的内容并排序；然后删除重复的页面。
    - 结果就是工作集
    - 维护移位寄存器并在缺页中断时处理它所需要的开销很大
  - 一种常见的近似方法就是
    - 不是向后找最近k次的内存访问，而是考虑其执行时间
    - 当前实际运行时间
      - 一个进程从它开始执行到当前所实际使用的CPU时间总数
    - 进程的工作集可以被称为在过去的τ秒实际运行时间中它所访问过的页面的集合
- 基于工作集的页面置换算法
  - 基本思路是找出一个不在工作集中的页面并淘汰它
  - 每个表至少包含两条信息：
    - 上次使用该页面的近似时间和R（访问）位
  - 空白的矩形表示该算法不需要的其他域，如页框号、保护位、M（修改）位
  - 该算法工作方式
    - 在处理每个表项时，都需要检查R位
      - 如果它是1，就把当前实际时间写进页表项的“上次使用时间”域，以表示缺页中断发生时该页面正在被使用
      - 如果R是0，那么表示在当前时钟滴答中，该页面还没有被访问过，则它就可以作为候选者被置换
      - 如果R是0同时生存时间小于或等于τ，则该页面仍然在工作集中
        - 这样就要把该页面临时保留下来，但是要记录生存时间最长（“上次使用时间”的最小值）的页面

### 3.4.9 工作集时钟页面置换算法

- 当缺页中断发生后，需要扫描整个页表才能确定被淘汰的页面
  - 因此基本工作集算法是比较费时的
- WSClock，工作集时钟算法
  - 基于时钟算法，并且使用了工作集信息
  - 与时钟算法一样，所需的数据结构是一个以页框为元素的循环表
    - 每个表项包含来自基本工作集算法的上次使用时间，以及R位（已标明）和M位（未标明）
  - 与时钟算法一样，每次缺页中断时，首先检查指针指向的页面
    - 如果R位被置为1，该页面在当前时钟滴答中就被使用过，那么该页面就不适合被淘汰
    - 现在来考虑指针指向的页面在R=0时
      - 如果页面的生存时间大于τ并且该页面时干净的，它就不在工作集中，并且在磁盘上有一个有效的副本
  - 原则上，所有的页面都有可能因为磁盘I/O在某个时钟周期被调用
  - 如果指针经过一圈返回它的起始点，有两种情况
    - 至少调度了一次写操作
      - 指针仅仅是不停地移动，寻找一个干净页面
    - 没有调度过写操作
      - 所有的页面都在工作集中，否则将至少调度一个写操作

### 3.4.10 页面置换算法小结

|      算法       |      注释      |
| :-----------: | :----------: |
|     最优算法      | 不可实现，但可用作基准  |
| NRU（最近未使用）算法  |  LRU的很粗糙的近似  |
| FIFO（先进先出）算法  |   可能抛弃重要页面   |
|    第二次机会算法    |  比FIFO有大的改善  |
|     时钟算法      |     现实的      |
| LRU（最近最少使用）算法 |  很优秀，但很难实现   |
| NFU（最不经常使用）算法 | LRU的相对粗略的近似  |
|     老化算法      | 非常近似LRU的有效算法 |
|     工作集算法     |   实现起来开销很大   |
|    工作集时钟算法    |    好的有效算法    |

- 最优算法在当前页面中置换最后要访问到的页面
  - 不能使用，可以作为衡量其他算法得基准
- NRU算法根据R位和M位的状态吧页面分为四类
  - 该算法易于实现，但是性能不是很好，还存在更好的算法
- FIFO算法通过维护一个页面的链表来记录它们装入内存的顺序
  - 淘汰的是最老的页面，但是该页面可能仍在使用
- 第二次机会算法是对FIFO算法的改进，它移出页面前先检查该页面是否正在被使用
  - 这个改进大大提高了性能
  - 时钟算法是第二次机会算法得另一种实现
    - 它具有相同的性能特征，而且只需要更少的执行时间
- LRU算法是一种非常优秀的算法，但是只能通过特定的硬件来实现
  - NFU是一种近似于LRU的算法，它的性能不是非常好
    - 老化算法更近似于LRU并且可以更有效地实现，是一个很好地选择
- 工作集算法有合理的性能，但它的实现开销较大
  - 工作集时钟算法是它的一种变体，不仅具有良好的性能，并且还能高效地实现
- 总之，最好的两种算法是老化算法和工作集时钟算法，它们分别基于LRU和工作集
  - 它们都具有良好页面调度性能，可以有效地实现

## 3.5 分页系统中的设计问题

- 为了使分页系统达到较好的性能，操作系统设计者必须仔细考虑的一些其他问题

### 3.5.1 局部分配策略与全局分配策略

- 怎样在互相竞争的可运行进程之间分配内存
  - local，局部页面置换算法
    - 局部算可以有效地为每个进程分配固定的内存片段
  - global，全局页面置换算法
    - 全局算法在可运行进程之间动态地分配页框
- 全局算法在通常情况下工作得比局部算法好
  - 若使用局部算法，即使有大量的空闲框存在，工作集的增长也会导致颠簸。
  - 如果工作集缩小了，局部算法又会浪费内存
  - 在使用全局算法时，系统必须不停地确定应该给每个进程分配多少页框
    - 监测工作集的大小
      - 不能防止颠簸
    - 使用一个为进程分配页框的算法
      - 定期确定进程运行的数目并为它们分配相等的份额
      - 采用按照进程大小的比例来为它们分配相应数目的页面的方法来取代上一种方法
- PFF，Page Fault Frequency，缺页中断率算法
  - 管理内存动态分配的一种方法
  - 它仅仅控制分配集的大小
- 有一大类页面置换算法（包括LRU在内），缺页中断率都会随着分配的页面的增加而降低，这是PFF背后的假定
  - 缺页中断率是分配的页框数的函数
  - 测量缺页中断率的方法是直截了当的：
    - 计算每秒的缺页中断率，可能也会将过去数秒的情况做连续平均
    - 一个简单的方法是将当前这一秒的值加到当前的连续平均值上然后除以2
- 一些页面置换算法既适用于局部置换算法，又适用于全局置换算法
  - FIFO算法
  - LRU
- 其他的页面置换算法，只有采用局部策略才有意义
  - 特别是工作集和WSClock算法是针对某些特定进程的而且必须应用在这些进程的上下文中

### 3.5.2 负载控制

- 即使是使用最优页面置换算法并对进程采用理想的全局页框分配，系统也可能发生颠簸
  - 该现象的症状之一就是如PFF算法所指出的，一些进程需要更多的内存，但是没有进程需要更少的内存
  - 惟一现实的解决方案就是暂时从内存中去掉一些进程
- 减少竞争内存的进程数的一个好方法是将一部分进程交换到磁盘，并释放他们所占用的所有页面
- 将进程交换出去以减轻内存需求的压力是借用了两级调度的思想
  - 一些进程被放到磁盘中，
  - 用一个短期的调度程序来调度剩余的进程
- 另一个需要考虑的因素是多道程序设计的道数

### 3.5.3 页面大小

- 页面大小是操作系统可以选择的一个参数
- 要确定最佳的页面大小需要在几个互相矛盾的因素之间进行权衡
  - 从结果上看，不存在全局最优
  - 选择小页面的两个因素
    - internal fragmentation，内部碎片
      - 在内存中有n个段、页面大小为p字节时，会有np/2字节被内部碎片浪费
    - 与小页面相比，大页面使用更多没有用的程序保留在内存中
  - 页面小意味着程序需要更多的页面，这又意味着更大的页表
  - 在某些机器上，每次CPU从一个进程切换到另一个进程时都必须把新进程的页表装入硬件寄存器中国
    - 页面越小意味着装入页面寄存器话费的时间就越长
    - 页表的空间也会随着页面的减小而增大
  - 从数学上分析
    - 假设进程大小是s个字节，页面大小是p个字节，每个页表项需要e个字节
    - 每个进程需要的页数大约是s/p，占用了se/p个字节的页表空间
    - 内部碎片在最后一页浪费的内存是p/2
    - 由页表和内部碎片损失造成的全部开销是以下两项之和
      - 开销=se/p+p/2
      - 通过对p一次求导并令右边等于零，我们得到方程：
        - -se/p²+1/2=0
      - 从这个方程可以得出最优页面大小的公式
        - $P=\sqrt{2se}$

### 3.5.4 分离的指令空间和数据空间

- 大多数计算机只有一个地址空间，既存放程序也存放数据
- 然后，地址空间通常太小了，这就使得程序员对地址空间的使用出现困难
- 首先在PDP-11（16位）上实现的一种解决方案是，为指令（程序正文）和数据设置分离的地址空间，分别称为I空间和D空间
  - 在使用这种设计的计算机中，两种地址空间都可以进行分页，而且互相独立
    - 不会引入任何复杂的设计，而且还能使可用的地址空间加倍

### 3.5.5 共享页面

- 另一个设计问题是共享
  - 在大型多道程序设计系统中，几个不同的用户同时运行同一个程序是很常见的
- 这里存在一个问题
  - 只读的页面（诸如程序文本）可以共享，但是数据页面则不能共享
- 如果系统支持分离的I空间和D空间
  - 页表与进程表数据结构无关
  - 每个进程在它的进程表中都有两个指针：
    - 一个指向I空间页表
    - 一个指向D空间页表
- 在两个或跟多进程共享某些代码时，在共享页面上存在一个问题
  - 共享数据要比共享代码麻烦
    - 在分页系统中，通常是让这些进程分别拥有它们自己的页表，但都指向同一个页面集合
      - 然而，所有映射到两个进程的数据页面都是只读的
    - 写时复制
      - 从来不会执行写操作的页面（包括所有程序页面）是不需要复制的，只有实际修改的数据页面需要复制

### 3.5.6 共享库

- 可以使用其他的粒度取代单个页面来实现共享
  - 如果一个程序被启动两次，大多数操作系统会自动共享所有的代码页面，而在内存中只保留一份代码页面的副本
  - 依赖于不同的操作系统，每个进程都拥有一份数据页面的私有副本，或者这些数据页面被共享并且被标记为只读
- 现代操作系统中，有很多大型库被众多进程使用
- 共享库，在Windows中称作DLL或动态链接库
  - 传统的链接
    - 当链接一个程序时，要在链接器的命令中指定一个或多个目标文件，可能还包括一些库文件
    - undefined enternals，未定义外部函数
      - 任何在目标文件中被调用了但是没有被定义的函数（比如，printf）
    - 链接器会在库中寻找这些未定义外部函数
      - 如果找到了，则将他们加载到可执行二进制文件中
    - 静态连接上百个包括这些库的程序会浪费大量的磁盘空间，在装载这些程序时也会浪费大量的内存空间
      - 因为系统不知道它可以共享这些库
  - 共享库
    - stub routine，存根例程
      - 当一个程序和共享库（与静态库有些许区别）链接时，链接器没有加载被调用的函数，而是加载了一小段能够在运行时绑定被调用函数的存根例程
    - 当一个共享库被装载和使用时，整个库并不是一次性地读入内存，而是根据需要，以页面为单位装载的
      - 因此没有调用到的函数是不会被装载到内存中的
    - 除了可以使可执行文件更小、节省内存空间之外，共享库还有一个优点：
      - 如果共享库中的一个函数因为修正一个bug被更新了，那么并不需要重新编译调用了这个函数的程序
    - 共享库带来了一个必须解决的小问题
      - 被两个进程共享的库被不同的进程定位在不同的地址上
      - 解决它的一个办法是写时复制，并为每一个共享这个库的进程创建新页面，在创建新页面的过程中进行重定位
      - 在编译共享库时，用一个特殊的编译选项告知编译器，不要产生使用绝对地址的指令
        - 相反，只能产生使用相对地址的指令
        - position-independent code，位置无关代码
          - 只使用相对偏移量的代码

### 3.5.7 内存映射文件

- memory-mapped file，内存映射文件
  - 一种更为通用的机制
  - 共享库实际上是内存映射文件的一个特例
  - 进程可以通过发起一个系统调用，将一个文件映射到其虚拟地址空间的一部分
- 内存映射文件提供了一种I/O的可选模型
  - 可以把一个文件当作一个内存中的大字符数组来访问，而不用通过读写操作来访问这个文件
  - 如果两个或两个以上的进程同时映射了同一个文件，它们就可以通过共享内存来通信

### 3.5.8 清除策略

- paging daemon，分页守护进程
  - 如果发生缺页中断时系统中有大量的空闲页框，此时分页系统工作在最佳状态
  - 为保证有足够的空闲页框，很多分页系统有一个称为分页守护进程的后台进程
  - 它在大多数时候睡眠，但定期被唤醒以检查内存的状态
- 在任何情况下，页面中原先的内容都被记录下来
- 一种实现清除策略的方法就是使用一个双指针时钟
  - 前指针由分页守护进程控制
  - 后指针用于页面置换

### 3.5.9 虚拟内存接口

- 允许程序员对内存映射进行控制的一个原因
  - 为了允许两个或者多个进程共享同一部分内存
  - 高带宽的共享
    - 一个进程往共享内存中写内容而另一个从中读出内容
- 页面共享可以用来实现高性能的消息传递系统
  - 发送进程清除那些包含消息的页面的映射，而接收进程把它们映射进来
- 另外一种高级存储管理技术是分布式共享内存
  - 允许网络上的多个进程共享一个页面集合，这些页面可能（而不是必要的）作为单个的线性共享地址空间

## 3.6 有关实现的问题

- 实现虚拟内存系统要在主要的理论算法（如第二次机会算法与老化算法，局部页面分配与全局页面分配，请求调页与预先调页）之间进行选择
- 但同时也要注意一系列实际的实现问题

### 3.6.1 与分页有关的工作

- 操作系统要在下面的四段时间里做分页相关的工作：
  - 进程创建时
    - 作系统要确定程序和数据在初始时有多大，并为它们创建一个页表
    - 操作系统还要在内存中为页表分配空间并对其进行初始化
    - 操作系统要在磁盘交换区中分配空间，以便在一个进程换出时再磁盘上有放置此进程的空间
    - 操作系统还要用程序正文和数据对交换区进行初始化
    - 操作系统必须把有关页表和磁盘交换区的信息存储在进程表中
  - 进程执行时
    - 必须为新进程重置MMU，刷新TLB，以清除以前的进程遗留的痕迹
    - 有时，在进程初始化时可以把进程的部分或者全部页面装入内存中以减少缺页中断的发生
  - 缺页中断时
    - 操作系统必须通过读硬件寄存器来确定是哪个虚拟地址造成了缺页中断
    - 最后，还要备份程序计数器，使程序计数器指向引起缺页中断的指令，并重新执行该指令
  - 进程终止时
    - 操作系统必须释放进程的页表、页面和页面在硬盘上所占用的空间

### 3.6.2 缺页中断处理

- 缺页中断发生时的事件顺序
  - 硬件陷入内核，在堆栈中保存程序计数器
  - 启动一个汇编代码例程保存通用寄存器和其他易失的信息，以免被操作系统破坏
  - 当操作系统发现一个缺页中断时，尝试发现需要哪个虚拟页面
  - 一旦知道了发生缺页中断的虚拟地址，操作系统检查这个地址是否有效，并检查存取与保护是否一致
  - 如果选择的页框“脏”了，安排该页写回磁盘，并发生一次上下文切换，挂起产生缺页中断的进程，让其他进程运行直至磁盘传输结束
  - 一旦页框“干净”后（无论是立刻还是在写回磁盘后），操作系统查找所需页面在磁盘上的地址，通过磁盘操作将其装入
  - 当磁盘中断发生时，表明该页已经被装入，页表已经更新可以反映它的位置，页框也被标记为正常状态
  - 恢复发生缺页中断指令以前的状态，程序计数器重新指向这条指令
  - 调度引发缺页中断的进程，操作系统返回调用它的汇编语言例程
  - 该例程恢复寄存器和其他状态信息，返回到用户空间继续执行，就好像缺页中断没有发生过一样

### 3.6.3 指令备份

- 当程序访问不在内存中的页面时，引起缺页中断的指令会半途停止并引发操作系统的陷阱

  - 在操作系统取出所需的页面后，它需要重新启动引起陷阱的指令

- 在最坏情形下考察这个问题的实质

  - 考虑一个有双地址指令的CPU，比如Motorola 680x0 ，这是一种在嵌入式系统中广泛使用的CPU

    - 指令

    ```c
    MOVE.L#6(A1),2(A0)
    ```

  - 一些680x0体系结构的寻址方式采用自动增量，这也意味着执行这条指令的副作用会增量一个或多个寄存器 

- 在某些计算机上，CPU的设计者们提供了一种解决方案，就是通过使用一个隐藏的内部寄存器

### 3.6.4 锁定内存中的页面

- 尽管本章对I/O的讨论不多，但计算机有虚拟内存并不意味着I/O不起作用了
- 虚拟内存和I/O通过微妙的方式互相作用着
- 如果分页算法是全局算法，包含I/O缓冲区的页面会有很小的机会（但不是没有）被选中换出内存
  - pinning，钉住
    - 锁住一个页面通常称为在内存中钉住（pinning）页面
  - 在内核缓冲区中完成所有的I/O操作，然后再将数据复制到用户页面

### 3.6.5 后备存储

- 当页面被换出时会存放在磁盘的哪个位置
- 在磁盘上分配页面空间最简单的算法
  - 在磁盘上设置特殊的交换分区，甚至从文件系统划分一块独立的磁盘（以平衡I/O负载）
    - 大多数UNIX是这样处理的
    - 在这个分区里没有普通的文件系统
    - 当系统启动时，该交换分区为空，并在内存中以单独的项给出它的起始和大小
    - 交换分区以空闲块列表的形式组织
- 与每个进程对应的是其交换区的磁盘地址，即进程映像所保存的地方
  - 写回一个页面时，计算写回地址的过程很简单：将虚拟地址空间中页面的偏移量加到交换区的开始地址
  - 但在进程启动前必须初始化交换
    - 一种方法是将整个进程映像复制到交换区，以便随时可将所需内容装入
    - 将整个进程装入内存，并在需要时换出
  - 但这种简单模式有一种问题：
    - 进程在启动后可能增大，尽管程序正文通常是固定的，但数据有时会增长，堆栈也总是在随时增长
    - 最好为正文、数据和堆栈分别保留交换区，并且允许这些交换区在磁盘上多于一个块
- 另一个极端的情况是事先什么也不分配，在页面换出时为其分配磁盘空间，并在换入时回收磁盘空间，这样内存中的进程不必固定于任何交换空间
  - 缺点是内存中每个页面都要记录相应的磁盘地址
- 不能保证总能够实现固定的交换分区
  - 没有磁盘分区时
    - 在这种情况下，可以利用正常文件系统中的一个或多个较大的、事前定位的文件
      - Windows就使用这个方法
  - 由于程序正文通常是只读的，当内存资源紧张、程序页不得不溢出内存时，尽管丢弃它们，在需要的时候再从可执行文件读入即可

### 3.6.6 策略和机制的分离

- 控制系统复杂度的一种重要方法就是把策略从机制中分离出来
  - 通过使大多数存储管理器作为用户级进程运行，就可以把该原则应用到存储管理中
- 基于Mach
  - 存储管理系统被分为三个部分
    - 一个底层MMU处理程序
      - 所有关于MMU工作的细节都被封装在MMU处理程序中
        - 该程序代码是与机器相关的
        - 操作系统每应用到一个新平台就要被重写一次
    - 一个作为内核一部分的缺页中断处理程序
      - 缺页中断处理程序是与机器无关的代码
        - 包含大多数分页机制
    - 一个运行在用户空间中的外部页面调度程序
      - 策略主要由作为用户进程运行的外部页面调度程序所决定
- 当一个进程启动时，需要通知外部页面调度程序以便建立进程页面映射
  - 如果需要的话还要在磁盘上分配后备存储
- 当进程正在运行时，它可能要把新对象映射到它的地址空间，所以还要再一次通知外部页面调度程序
- 这个实现方案没有给出放置页面置换算法的位置
  - 把它放在外度页面调度程序中比较简单，但会有一些问题
    - 外部页面调度程序无权访问所有页面的R位和M位
  - 需要某种机制把该信息传递给外部页面调度程序，或者把页面置换算法放到内核中
  - 两种方法中，外部页面调度程序都把数据写到磁盘上
  - 这种实现的主要优势是
    - 有更多的模块化代码和更好的适应性
  - 主要缺点是
    - 由于多次交叉“用户-内核”边界引起的额外开销
    - 系统模块间消息传递所造成的额外开销
  - 从长远来看，对于大多数实现，为了获得更高的可靠性而牺牲一些性能也是可以接受的

## 3.7 分段

- 对许多问题来说，有两个或多个独立的地址空间可能比只有一个要好得多
- 一个编译器在编译过程中会建立许多表，其中可能包括：
  - 被保存起来供打印清单用的源程序代码
  - 符号表，包含变量的名字和属性
  - 包含用到的所有整型量和浮点常量的表
  - 语法分析树，包含程序语法分析的结果
  - 编译器内部过程调用使用的堆栈
- 在一维地址空间中，当有多个动态增加的表时，一个表可能会与另一个表发生碰撞
  - 一种可能的方法就是从拥有过量空间的表中拿出一些空间给拥有极少量空间的表
- segment，段
  - 一个只观并且通用的方法
  - 在机器上提供多个互相独立的地址空间
  - 每个段由一个从0到最大的线性地址序列构成
  - 各个段的长度可以是0到某个允许的最大值之间的任何一个值
  - 不同的段的长度可以不同，并且通常情况下也都不相同
  - 段的长度可以动态地改变                                                                                                                                                                                                                                                                                                                                                         
- 因为每个段都构成了一个独立的地址空间，所以它们可以独立的增长或减小而不会影响到其他的段
- 段是一个逻辑实体，程序员知道这一点并把它作为一个逻辑实体来使用
  - 一个段可能包括一个过程、一个数组、一个堆栈、一个数值变量
  - 但一般它不会同时包含多个不同类型的内容
- 除了能简化对长度经常变动的数据结构的管理以外，分段存储管理还有其他一些优点
  - 如果每个过程都位于一个独立的段中并且起始地址是0，那么把单独编译好的过程链接起来的操作就可以得到很大的简化
  - 分段也有助于在几个进程之间共享过程和数据
    - shared library
- 因为每个段是一个为程序员所知道的逻辑实体，比如一个过程、一个数组或一个堆栈，故不同的段可以有不同种类的保护

|         考察点          |            分页             |                 分段                 |
| :------------------: | :-----------------------: | :--------------------------------: |
|  需要程序员了解正在使用这种技术吗？   |             否             |                 是                  |
|     存在多少线性地址空间？      |             1             |                 许多                 |
| 整个地址空间可以超出物理存储器的大小吗？ |             是             |                 是                  |
|  过程和数据可以被区分并分别被保护吗？  |             否             |                 是                  |
|   其大小浮动的表可以很容易提供吗？   |             否             |                 是                  |
|     用户间过程的共享方便吗？     |             否             |                 是                  |
|      为什么发明这种技术       | 为了得到大的线性地址空间而不必购买更大的物理存储器 | 为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护 |

- 页面的内容在某种程度上是随机的，程序员甚至察觉不到分页的事实
- 在分段系统中，由于用户会认为所有的段都一直在内存中，也就是说他可以当作所有这些段都在内存中那样去访问

### 3.7.1 纯分段的实现

- 分段和分页的实现本质上是不同的
  - 页面是定长的而段不是
- external fragmentation，外部碎片或棋盘形碎片
  - 在系统运行一段时间后内存被划分为许多块，一些块包含着段，一些则成了空闲区
  - 空闲区的存在使内存被浪费了，而这可以通过内存紧缩来解决

### 3.7.2 分段和分页结合：MULTICS

- 如果一个段比较大，把它整个保存在内存中可能很不方便甚至是不可能的，因此产生了对它进行分页的想法
- MULTICS
  - 第一个实现了这种支持的系统
  - MULTICS运行在Honeywell 6000计算机和它的一些后继机型上
  - 它为每个程序提供了最多$2^{18}$ （超过250000个），每个段的虚拟地址空间最长为65536（36位）字长
  - 为了实现它，MULTICS的设计者决定把每个段都看做是一个虚拟内存并对它进行分页，以结合
    - 分页的优点
      - 统一的页面大小
      - 只使用段的一部分时把它全部调入内存
    - 分段的优点
      - 易于编程
      - 模块化
      - 保护和共享
- 每个MULTICS程序都有一个段表，每个段对应一个描述符
  - 段表本身也是一个段并被分页
  - 一个段描述符包含了一个段是否在内存中的标志
    - 描述符中只需要18位来存储页表地址
      - 因为物理地址是24位并且页表是按照64字节的边界对齐的，这隐含着页面地址的低6位是000000
    - 段描述符中还包含了段大小、保护位以及其他的一些条目
- 每个段都是一个普通的虚拟地址空间，用非分段式分页存储相同的方式进行分页
- MULTICS中一个地址由两部分构成：
  - 段
  - 段内地址
    - 页号
    - 页内的字
- 进行内存访问时，执行下面的算法：
  - 根据段号找到段描述符
  - 检查该段的页表是否在内存中
  - 检查所请求虚拟页面的页表项
  - 把偏移量加到页面的起始地址上，得到要访问的字在内存中的地址
  - 最后进行读或写操作
- 如果对于每条指令都由操作系统来运行上面所述的算法，那么程序就会运行得很慢
  - 实际上，MULTICS硬件包含了16个字的高速TLB，对给定的关键字它能并行搜索所有的表项
  - TLB保存着16个最近访问页的地址，工作集小于TLB容量的程序将随着整个工作集的地址被装入TLB中而逐渐达到稳定

### 3.7.3 分段和分页的结合：Intel Pentium

- Pentium处理器的虚拟内存存在许多方面都与MULTICS类似
  - MULTICS有256K个独立的段，每个段最长可以有64K个36位字
  - Pentium处理器有16K个独立的段，每个段最多可以容纳10亿个32位字
- Pentium处理器中虚拟内存的核心是两张表
  - LDT，Local Descriptor Table，局部描述符表
    - 每个程序都有自己的LDT
    - LDT描述局部于每个程序的段，包括其代码、数据、堆栈等
  - GDT，Global Descriptor Table，全局描述符表
    - 同一台计算机上的所有程序共享一个GDT
    - GDT描述系统段，包括操作系统本身
- selector，选择子
  - 为了访问一个段，一个Pentium程序必须把这个段的选择子装入机器的6个段寄存器的某一个中
  - CS寄存器保存代码段的选择子
  - DS寄存器保存数据段的选择子
- 选择子中的一位指出这个段是局部的还是全局的（即它是在LDT还是在GDT中），其他的13位是LDT或GDT的表项编号
  - 还有两位和保护有关
- 在选择子被装入段寄存器时，对应的描述符被从LDT或GDT中取出装入微程序寄存器中，以便快速地访问
  - 一个描述符由8个字节构成，包括段的基地址、大小和其他信息
- 选择子的格式经过合理设计，使得根据选择子定位描述符十分方便
- Limit，段长度域
  - 硬件根据Limit域检查偏移量是否超出了段的结尾
- linear address，线性地址
  - 假设段在内存中并且偏移量也在范围内，Pentium处理器接着把描述符中32位的基址和偏移量相加形成线性地址
  - 基址允许每个段的起始地址位于32位线性地址空间内的任何位置
- 在禁止分页时，我们就得到了一个纯的分段方案
- Page directory，页目录
  - 每个运行程序都有一个由1024个32位表项组成的页目录
  - 它通过一个全局寄存器来定位
  - 这个目录中的每个目录项都指向一个也包含1024个32位表项的页表，页表项指向页框
- 线性地址被分为三个域
  - 目录
    - 被作为索引在页目录中找到指向正确的页表的指针
  - 页面
    - 被用作索引在页表中找到页框的物理地址
  - 偏移量
    - 被加到页框的地址上得到需要的字节或字的物理地址
- 每个页表项是32位，其中20位是页框号
  - 其余的位包含了由硬件设置供操作系统使用的访问位和“脏”位、保护位和一些其他有用的位
  - 每个页表有描述1024个4KB页框的表项，因此一个页表可以处理4MB的内存
    - 这样短的段的开销只是两个页面，而不是一级页表时的100万个页面
- 为了避免重复的内存访问，Pentium处理器和MULTICS一样
  - 有一个小的TLB把最近使用过的“目录-页面”二元组映射为页框的物理地址
- 如果某些应用程序不需要分段，而是需要一个单独的、分页的32位地址空间
  - 所有的段寄存器可以用同一个选择子设置，其描述符中基址设为0，段长度被设置为最大
  - 所有当前的Pentium操作系统都是这样工作的
  - OS/2是惟一一个使用Intel MMU体系结构所有功能的操作系统
- 和虚拟内存一样，Pentium处理器的保护系统与MULTICS很类似
  - 它支持4个保护级，0级权限最高，3级最低
  - 当程序只使用与它同级的段时，一切都会很正常
  - 对更高级别数据得存取是允许的
  - 对更低级别的数据的存取是非法的并会引起陷阱
- call gate，调用门
  - 为执行越级调用，CALL指令必须包含一个选择子而不单单是一个地址
  - 选择子指向一个称为调用门的描述符
  - 由它给出被调用过程的地址
- protection ring，保护环
  - 保护级和调用门的概念来自MUTICS，称为保护环
- 一种典型的应用
  - 在0级是操作系统内核
    - 处理I/O、存储管理和其他关键的操作
  - 在1级是系统调用处理程序
    - 用户程序可以通过调用这里的过程执行系统调用
  - 在2级是库过程
    - 它可能是由很多正在运行的程序共享的
  - 在3级上的用户程序受到的保护最少
- 陷阱和中断使用了一种和调用门类似的机制

## 3.8 有关存储管理的研究

- 存储管理，特别是页面置换算法
  - 曾经是一个成果丰硕的研究领域
- 很多实时系统试图使用时钟算法得某些变体
  - 因为它容易实现而且相对高效
- 现在仍有一些关于心事系统的分页研究正在进行
- 关于分页性能的研究也在进行
  - 研究的兴趣还包括多媒体系统和实时系统的存储器管理

## 3.9 小结

- 在最简单的系统中是根本没有任何交换和分页的
- 交换技术
  - 系统通过交换技术可以同时运行总内存占用超过物理内存大小的多个进程
- 虚拟内存
  - 页面
    - 每一个进程的地址空间被划分为同等大小的块
  - 页面可以被放入内存中任何可用的页框内
  - 有多种页面置换算法
    - 其中比较好的算法是老化算法和工作集时钟算法
- 为了使分页系统工作良好，还要关注
  - 工作集的确定
  - 存储器分配策略
  - 所需要的页面大小
- 分段
  - 可以帮助处理再执行过程中大小有变化的数据结构
  - 并能交换连接和共享
  - 还有利于为不同的段提供不同的保护
  - 可以把分段和分页结合起来，以提供一种二维的虚拟内存
    - MULTICS
    - Pentium

## 习题

1. 这是一个巧合。基址寄存器的值为16384是因为程序恰好在地址16384上加载。程序可以字任何地方加载。界限寄存器为16384是因为程序具有16384字节的长度。程序可以有任意的长度。加载地址与程序长度仅仅是一种巧合
2. 由题意得，读或写每个字节需要$10/4=2.5ns$ 且$128MB=2^{27}$ 字节，内存紧缩时，几乎整个内存都必须复制，也就是要求读出每一个内存字，然后重写到不同的位置。因此，对于每个字节的压缩需要$5ns$ ，故总共需要的时间为$2^{27}×5ns=671ms$ 
3. $128MB=2^{27}$ 字节。对于位图，用于存储管理需要$2^{27}/8n$ 字节，故总共需要$2^{27}+2^{27}/8n=2^{27}×(1+1/8n)$ 字节；对于链表，用于存储管理需要$2^{27}/2^{16}=2^{11}$ 个节点，每个节点大小为需要$(32+16+16)/8=8$ 字节，故总共需要$2^{27}+2^{11}×8=2^{27}+2^{11}=2^{27}×(1+1/8×2^{10})$ ；因此，当$n<2^{10}$ 字节（即1KB）时，位图>链表，则使用链表；当n>1KB时，位图<链表，则使用位图
4. 首次适配：20KB，10KB，18KB

最佳适配：12KB，10KB，9KB

最差适配：20KB，18KB，15KB

下次适配：20KB，18KB，9KB

1. ​

2. | 虚拟地址  |   4KB页面（12为偏移量）    | 8KB页面（132为偏移量）     |
   | :---: | :----------------: | ------------------ |
   | 20000 | 100\|111000100000  | 10\|0111000100000  |
   | 32768 | 1000\|000000000000 | 100\|0000000000000 |
   | 60000 | 1110\|101001100000 | 111\|0101001100000 |

   它们制作了MMU，并连接在CPU与地址总线之间，这样从处理器进入MMU的地址全部视为虚拟地址，并被转换为物理地址，然后被送到地址总线，映射到内存中

3. a) int占4bit，M的最小值是1024，才能使内层循环的每次执行时都引起TLB失效，由于TLB有64个，所以N的值>64×M

   b) M的值应该大于1024才能在内层循环每次执行时引起TLB失效，但现在N的值要大于64K，所以X会超过256KB。当N的值足够大时，还是会引起TLB失效

4. 所有进程的整个虚拟地址空间为nv，这就是页面存储所需的。不过，可以在RAM中存储量为r，因此需要的磁盘存储量仅为nv-r。该量比实际所需的要大得多，因为极少有n个进程实际运行，而且这些进程也极少需要其最大允许的虚拟内存

5. 页大小为8KB，所以页内地址为13位，故页框有19位，可表示的物理空间有$2^{19}$ 。只考虑单进程，运行之前把所有页框复制到硬件的时间为$2^19×100ns=52.42ms$ ,故装入页表的时间比例为52.4288/100×100%=52.42%


1. a) 页面大小为4KB，即偏移量为12位，所以页表里的页表项有2^(48-12)=2^36个；

b) TLB访问的命中率达100%。在指令访问下一个页面之前读取数据得命中率是100%，一个4KB大小的页面包含1024个长整型数据，每访问1024个数据就会有一次TLB失效

1. 假设一个机器有38位的虚拟地址和32位的物理地址

a) 与一级页表比较，多级页表的主要优点是什么？

b) 一个有16KB个页、4字节表项的二级页表，应该对第一级页表域分配多少位，对第二级页表域分配多少位？请解释原因

答案：

a) 避免把全部页表保留在内存中

b) $ 2^{38}/2^{14}=2^{24} $ ，故页面长度为$2^{24}$ ，需要24位偏移量，而二级页表的表项为4字节，故$PT2=2$ ，所以$PT1=38-2-24=12$ 。因此，对第一级页表域配12位，对第二级页表分配域2位

1. 一个32位地址的计算机使用两级页表。虚拟地址被分成9位的项级页表域、11位的二级页表域和一个偏移量，页面大小是多少？在地址空间中一共有多少个页面？

答案：

偏移量$=32-9-11=12$ ,所以页面大小为：$2^{12}=4KB $ ,页面数为：$2^{20}$ 

1. 假设一个32位虚拟地址被分成a、b、c、d四个域。前三个域用于一个三级页表系统，第四个域d是偏移量。页面数与这四个域的大小都有关系吗？如果不是，与哪些因素有关以及与哪些因素无关？

答案：

页面数只依赖于a、b和c的和，至于它们之间是如何划分的是无关的

1. 一个计算机使用32位的虚拟地址，4KB大小的页面。程序和数据都为最低的页面（0~4095），堆栈位于最高的页面。如果使用传统（一级）分页，页表中需要多少个表项？如果使用两级分页，每部分有10位，需要多少个页表项？

答案：

对于一级分页，$2^{32}/2^{20}=2^{20}$ 个表项；对于二级分页，$2^{10}×4=2^{12}$ 个表项（顶级页表项、正文段、数据段和堆栈段二级列表）

1. 一台计算机的进程在其地址空间中有1024个页面，页表保存在内存中。从页表中读取一个字的开销是5ns。为了减小这一开销，该计算机使用TLB，它有32个（虚拟页面，物理页框）对，能在1ns内完成查找。请问把平均开销降到2ns需要的命中率是多少？

答案：

$1×x+(1-x)×(5+1)=2$

解得：

$x=80%$

1. VAX机中的TLB中没有包含R位，为什么？

答案：

TLB并不需要R位。只要页面存在，就表示页面已被引用；否则不会存在。因此这个位是完全冗余的。然而，当条目被写回内存时，内存表中的R位被置位

1. TLB需要相联存储设备如何用硬件实现，这种设计对拓展性意味着什么？

答案：

相联存储器本质上将键与多个寄存器的内容同时进行比较。对于每个寄存器，必须有一组比较器，将寄存器内容中的每个位与正在搜索的键进行比较。实现这种设备所需的门（或晶体管）的数量是寄存器数量的线性函数，因此这种设计对拓展性意味着成本变得高昂

1. 一台机器有48位虚拟地址和32位物理地址，页面 大小是8KB，试问页面中需要多少个表项

答案：

表项数为$2^{48}/2^{13}=2^{35}$ 

1. 一个计算机的页面大小为8KB，内存大小为256KB，虚拟地址空间为64GB，使用倒排页表实现虚拟内存。为了保证平均散列链的长度小于1，散列表应该多大？假设散列表的大小为2的幂

答案：内存有$2^{28}(256KB)/2^{13}(8KB)=(2^{15})32768$ 页。32K的哈希表的平均链长为1。为了使之小于1，必须使用下一个尺寸$(2^{16})65536$ 项。将32768项放入65536格中使其平均链长为0.5，以确保快速的查询

1. 一个学生在编译设计课程中向教授提议了一个项目：编写一个编译器，用来产生页面访问列表，该列表可以用来实现最优页面置换算法。试问这是否可能？为什么？有什么方法可以改进运行时的分页效率？

答案：

这是不可能的，除了程序的执行过程在编译时是完全可预测的少数情况。如果编译器收集程序有关调用代码中的位置信息，则可以在链接时使用此信息来重新排列目标代码，以便程序位于它们调用的代码附近。这将使得进程更可能与所调用的代码在同一个页面上。当然这从许多地方进行调用的程序来说是无效的

1. 假设虚拟页码索引流中有一些长的页码索引序列的重复，序列之后有时会使一个随机地页码索引。例如，序列0,1，...，511,431,0,1，...，511,332,0,1，...中就包含了0,1，...，511的重复，以及跟随在它们之后的随机页码索引431和332。

a) 在工作负载比该序列短的情况下，标准的页面置换算法（LRU，FIFO，Clock）在处理换页时为什么效果不好？

b) 如果一个程序分配了500个页框，请描述一个效果优于LRU、FIFO或Clock算法得页面置换方法

答案：

a) 标准的页面置换算法是针对已经在内存中的页面研究的。当工作负载比序列短时，会出现内存容量不够而长生颠簸，这种情况下LRU、Clock、FIFO算法达不到预期的效果

b) 如果分配了500个页框，那么0~498号页框是固定的，只有一个页框在进行页面置换

1. 如果将FIFO页面置换算法用到4个页框和8个页面上，若初始时页框为空，访问字符串为0172327103，请问会发生多少次缺页中断？如果使用LRU算法呢？

答案：FIFO的页框如下：

  0172327103

x0172333300

xx017222233

xxx01777722

xxxx0111177

oppppooopp



LRU的页框如下：

  0172327103

x0172327103

xx017232710

xxx01773271

xxxx0111327

oppppooopp

FIFO发生6次缺页中断，LRU发生7次缺页中断

1. 考虑图3-15b中的页面序列。假设从页面B到页面A的R位分别是11011011。使用第二次机会算法，被移走的是哪个页面？

答案：

01101100

1. 一台小计算机有4个页框。在第一个时钟滴答时R位是0111（页面0是0，其他页面是1），在随后的时钟滴答中这个值是1011、1010、1101、0010、1010、1100 、0001。如果使用带有8位计数器的老化算法，给出最后一个滴答后4个计数器的值。

答案：

计数器的值是：

第0页：01101110

第1页：01001001

第2页：00110111

第3值：10001011

1. 请给出一个页面访问序列，其第一个被选择置换的页面必须不同于Clock和LRU算法。假设一个进程分配了3个页框，访问串中的页号属于集合0,1,2,3

答案：

顺序：0,1,2,1,2,0,3。在LRU中，第1页将替换为第3页。在Clock中，第0页将被替换，因为所有的页面都将被标记，表针位于第0页。

1. 在图3-21c的工作集时钟算法中，表针指向那个R=0的页面。如果τ=400，这个页面将被移出吗？如果τ=1000呢？

答案：

该页面的生存的生存时间是2204-1213=991。如果τ=400，它就不在工作集中，最近没有被引用，所以它将被移出。τ=1000的情况不同，此时在工作集中，所以它不会被引用。

1. 把一个64K的程序从平均寻道时间10ms、旋转延迟时间10ms、每磁道32KB的磁盘上装入，对于下列页面大小分别需要多少时间？

a) 页面大小为2KB

b) 页面大小为4KB

假设页面随机地分布在磁盘上，柱面的数目非常大以至于两个页面在同一个柱面的机会可以忽略不计。

答案：

寻道加旋转延迟时间为20毫秒。对于2KB的页面，加载32个页面将需要640毫秒。对于4KB页面，加载16个页面需要320毫秒。

1. 一个计算机有4个页框，装入时间、上次访问时间和每个页的R位和M位如下所示（时间以时钟滴答为单位）：

|  页面  | 装入时间 | 上次访问时间 |  R   |  M   |
| :--: | :--: | :----: | :--: | :--: |
|  0   | 126  |  280   |  1   |  0   |
|  1   | 230  |  265   |  0   |  01  |
|  2   | 140  |  270   |  0   |  0   |
|  3   | 110  |  285   |  1   |  1   |

a) NRU算法将置换哪个页面？

b) FIFO算法将置换哪个页面？

c) LRU算法将置换哪个页面？

d) 第二次机会算法将置换哪个页面?

答案：

NRU算法：2

FIFO算法：3

LRU算法：1

第二次机会算法：2

1. 有二维数组：

```c
int X[64][64];
```

假设系统中有4个页框，每个页框大小为128个字（一个整数占用一个字）。处理数组X的程序正好放在一页中，而且总是占用0页号。数据会在其他3个页框中被换入或换出。数组X为按行存储（即，在内存中，$X[0][0] $ 之后是$x[0][1]$ ）。下面两段代码中，那一个会有最少的缺页中断？请解释原因，并计算缺页中断的总数。

答案：

答案：

依题，A段按列访问，B段按行访问。X数组按行存储，即每一页可存储2行（128字节）；每访问一次页框就发生一次缺页中断。A段：每访问一个

A段：

```c
for(int j=0;j<64;j++)
for(int i=0;i<64;i++)X[i][j]=0;
```

B段：

```c
for(int i=0;i<64;i++)
for(int j=0;j<64;j++)X[i][j]=0;	
```

1. PDP-1是最早的分时计算机之一，有4K个18位字的内存。在每个时刻它在内存中保持一个进程。当调度程序决定运行另一个进程时，将内存中的进程写到一个换页磁鼓上，磁鼓的表面有4K个18位字。磁鼓可以从任何字开始读写，而不仅仅是字0。请解释为什么要选这个磁鼓？

答案：

PDP-1磁鼓的优点是没有旋转延迟。每次记忆被写入鼓时，这节省了一半的旋转延迟。

1. 一台计算机为每个进程提供65526字节的地址空间，这个地址空间被划分为4096字节的页面。一个特定的程序有32768字节的正文、16386字节的数据和15870字节的堆栈。这个程序能装入这个地址空间吗？如果页面大小是512字节，能放得下吗？记住一个页面不能同时包含两个不同段的成分。

答案：

可用页面数：$65536/4096=16$ 

正文需要页面数：$32768/4096=8$

数据需要页面数：$16386/4096=4.0005$ 

堆栈需要页面数：$15870/4096=3.87$ 

总需要页面数：$8+5+4=17>16$ ，故不能装入这个地址空间

如果页面大小是512字节，可用页面数：$65535/512=128$ 

正文需要页面数：$32768/512=32.004$ （取33）

堆栈需要页面数：$15870/512=30.996$ （取31）

总需要页面数：$64+33+31=128$ ，故能装入这个地址空间

1. 一个页面同一时刻可能在两个工作集中吗？请解释原因。

答案：

如果页面可以共享，则可以。例如，如果分时系统的两个用户同时运行相同的编辑器，并且程序文本被共享而不是复制，那一些页面可能同时在每个用户的工作集中。

1. 人们已经观察到在两次缺页中断之间的指令数与分配给程序和页框数直接成比例。如果可用内存加倍，缺页中断间的平均间隔也加倍。假设一条普通指令需要1μs，但是如果发生了缺页中断就需要2001μs（即2ms处理缺页中断）。如果一个程序运行了60s，期间发生了15000次缺页中断，如果可用内存是原来的两倍，那么这个程序运行需要多少时间？

答案：

该程序发生了15000次缺页中断，每个缺页中断都需要2ms的额外处理时间。处理缺页中断的总开销为30s。这意味着在程序运行的60s内，一半用于缺页中断开销，一半用于运行程序。如果我们运行程序的内存是内存的两倍，我们会得到一半的内存页错误，只有15秒的页面错误开销，所以总的运行时间将是45秒。

1. Frugal计算机公司的一组操作系统设计人员正在考虑在它们的新操作系统中减少对后备存储数量的需求。老板建议根本不要把程序正文保存在交换区中，而是在需要的时候直接从二进制文件中调页而来。在什么条件下（如果有这样的条件的话）这种想法适用于程序文本？在什么条件下（如果有这样的条件的话）这种想法适用于数据？

答案：

这种想法适用于无法修改的程序和不能修改的数据。但是，通常程序不能修改，数据却极少数无法修改。如果二进制文件中的数据区被更新的页面覆盖，下一次程序启动时，它将不会有原始数据。

1. 有一条机器语言指令将要被调入，该指令可把32位字装入含有32位字地址的寄存器。这个指令可能引起的最大缺页中断次数是多少？

答案：

该指令可能跨越页面边界系统，为了获取指令将导致两个缺页中断。获取的字也可能跨越边界，产生两个以上的缺页中断，总共四个。如果字必须在内存中对齐，则数据字只能导致一个缺页中断，但是在某些机器（包括奔腾）上，在具有4KB页面的机器上的4094地址上加载32位字的指令是合法的。

1. 像在MULTICS中那样，当同事使用分段和分页时，首先必须查找段描述符，然后是页描述符。TLB也是这样按两级查找的方式工作的吗？

答案：

否。搜索键使用段号和虚拟页码，因此可以在单个匹配中找到确切的页面。

1. 一个程序中有两个段，段0中为指令，段1中为读/写数据。段0有读/执行保护，段1有读/写保护。内存是请求分页式虚拟内存系统，它的虚拟地址为4位页号，10位偏移量。页表和保护如下所示（表中的数字均为十进制）：

|  段0  |      |  段1  |      |
| :--: | :--: | :--: | :--: |
| 读/执行 |      | 读/写  |      |
| 虚拟页号 | 页框号  | 虚拟页号 | 页框号  |
|  0   |  2   |  0   | 在磁盘  |
|  1   | 在磁盘  |  1   |  14  |
|  2   |  11  |  2   |  9   |
|  3   |  5   |  3   |  6   |
|  4   | 在磁盘  |  4   | 在磁盘  |
|  5   | 在磁盘  |  5   |  13  |
|  6   |  4   |  6   |  8   |
|  7   |  3   |  7   |  12  |

对于下面的情形，或者给出动态地址所对应的实（实际）内存地址，或者指出发生了哪种失效（缺页中断，或保护错误）

a) 读取页：段1，页1，偏移3

b) 存储页：段0，页0，偏移16

c) 读取页：段1，页4，偏移28

d) 跳转页：段1，页3，偏移32

答案：

a) 读取，段1，符合保护要求，内存地址为（14,3）

b) 存储，段0，违反保护要求，保护错误；

c) 读取，段1，符合保护要求，页框在磁盘，发生缺页中断；

d) 跳转，段1，违反保护要求，保护错误。

1. 你能想象在那些情况下支持虚拟内存是个坏想法吗？不支持虚拟内存能得到什么好处呢？请解释。

答案：一般来说，当可以了解和控制所有应用程序的需求时，虚拟内存就没必要了。例如，特殊用途的处理器（如网络处理器），嵌入式处理器和超级计算机（如机翼设计）。在这些情况下，我们总会考虑使用更多的物理内存。如果操作系统没有使用（不支持）虚拟内存，它的代码会简单很多，系统的性能会有所提高。另一方面，一些来自虚拟内存的想法有利于开发，尽管有不同的设计需求。

1. 构造一个柱状图，计算你的计算机中可执行文件大小的平均值和中间值。在Windows系统中，观察所有的.exe和.dll文件；在UNIX系统中，观察/bin、/usr/bin、/local/bin目录下的所有的非脚本文件的可执行文件（或者使用file工具来查找所有的可执行文件）。确定这台机器的最优页面大小啊，只考虑代码（不包括数据）。考虑内部碎片和页表大小，对页表项的大小做出合理的假设。假设所有的程序被执行的可能性相同，所以可以同等对待。

答案：

1. MS-DOS中的小程序可以编译成.COM文件。这些文件总是装载到0x100地址的一个内存段，这个内存段用作代码、数据和堆栈。转移执行的控制指令（如JMP、CALL）和访问静态数据得指令把地址编译进目标代码中。写一个程序重定向这个程序文件，使之可以在任意开始地址处运行。读者的程序必须扫描代码，寻找指向固定内存地址的目标代码，然后重定向范围内修改那些指向内存单元的地址。可以在汇编语言程序正文中找到这些目标地址。注意，要想不借助于额外的信息就出色完成这项工作通常是不可能的，因为有些数据的值和指令目代码相仿。

答案：

1. 编写一个程序，说明TLB失效对有效内存存取时间的影响，内存存取时间可以用计算每次遍历大数组时的读取时间来衡量。

a) 解释编程思想，并描述所期望输出如何展示一些实际的虚拟内存体系结构。

b) 运行该程序，并解释运行结果与你的预期有何出入。

c) 在一台更古老的且有着不同体系且有着不同体系结构的计算机上重复b），并解释输出上的区别。

1. 编写一个程序，该程序能说明当有两个进程的简单情况下，使用局部页置换策略和全局页置换策略的差异。读者将会用到能生成一个基于统计模型的页面访问串的例程。这个模型有N个状态，从0到N-1，代表每个可能的页面访问，每个状态i相关的概率$p_i$ 代表下一次访问仍指向同一页面的几率。否则，下一次页面访问将以等概率指向其他任何一个页面。

a) 说明当N比较小时，页面访问串生成例程能运行正常。

b) 对有一个进程和固定数量的页框的情况计算缺页中断率。解释这种结果为什么是正确的。

c) 对有独立页面访问序列的两个进程，以及是b)中页框数两倍的页框，重复b)。

